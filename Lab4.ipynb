{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64069f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  int32  \n",
      " 2   County            72718 non-null  int32  \n",
      " 3   TotalPop          72718 non-null  int64  \n",
      " 4   Men               72718 non-null  int64  \n",
      " 5   Women             72718 non-null  int64  \n",
      " 6   Hispanic          72718 non-null  float64\n",
      " 7   White             72718 non-null  float64\n",
      " 8   Black             72718 non-null  float64\n",
      " 9   Native            72718 non-null  float64\n",
      " 10  Asian             72718 non-null  float64\n",
      " 11  Pacific           72718 non-null  float64\n",
      " 12  VotingAgeCitizen  72718 non-null  int64  \n",
      " 13  Income            72718 non-null  float64\n",
      " 14  IncomeErr         72718 non-null  float64\n",
      " 15  IncomePerCap      72718 non-null  float64\n",
      " 16  IncomePerCapErr   72718 non-null  float64\n",
      " 17  Poverty           72718 non-null  float64\n",
      " 18  ChildPoverty      72718 non-null  float64\n",
      " 19  Professional      72718 non-null  float64\n",
      " 20  Service           72718 non-null  float64\n",
      " 21  Office            72718 non-null  float64\n",
      " 22  Construction      72718 non-null  float64\n",
      " 23  Production        72718 non-null  float64\n",
      " 24  Drive             72718 non-null  float64\n",
      " 25  Carpool           72718 non-null  float64\n",
      " 26  Transit           72718 non-null  float64\n",
      " 27  Walk              72718 non-null  float64\n",
      " 28  OtherTransp       72718 non-null  float64\n",
      " 29  WorkAtHome        72718 non-null  float64\n",
      " 30  MeanCommute       72718 non-null  float64\n",
      " 31  Employed          72718 non-null  int64  \n",
      " 32  PrivateWork       72718 non-null  float64\n",
      " 33  PublicWork        72718 non-null  float64\n",
      " 34  SelfEmployed      72718 non-null  float64\n",
      " 35  FamilyWork        72718 non-null  float64\n",
      " 36  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int32(2), int64(6)\n",
      "memory usage: 20.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TractId  State  County  TotalPop   Men  Women  Hispanic  White  Black  \\\n",
       "0  1001020100      0      89      1845   899    946       2.4   86.3    5.2   \n",
       "1  1001020200      0      89      2172  1167   1005       1.1   41.6   54.5   \n",
       "2  1001020300      0      89      3385  1533   1852       8.0   61.4   26.5   \n",
       "3  1001020400      0      89      4267  2001   2266       9.6   80.3    7.1   \n",
       "4  1001020500      0      89      9965  5054   4911       0.9   77.5   16.4   \n",
       "\n",
       "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0     0.0  ...   0.5          0.0         2.1         24.5       881   \n",
       "1     0.0  ...   0.0          0.5         0.0         22.2       852   \n",
       "2     0.6  ...   1.0          0.8         1.5         23.1      1482   \n",
       "3     0.5  ...   1.5          2.9         2.1         25.9      1849   \n",
       "4     0.0  ...   0.8          0.3         0.7         21.0      4787   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         74.2        21.2           4.5         0.0           4.6  \n",
       "1         75.9        15.0           9.0         0.0           3.4  \n",
       "2         73.3        21.1           4.8         0.7           4.7  \n",
       "3         75.8        19.7           4.5         0.0           6.1  \n",
       "4         71.4        24.1           4.5         0.0           2.3  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('acs2017_census_tract_data.csv')\n",
    "#df.info()\n",
    "df = df.dropna()\n",
    "#df.info()\n",
    "df[['State', 'County']] = df[['State','County']].apply(LabelEncoder().fit_transform)\n",
    "df.info()\n",
    "df.head()\n",
    "#[.5 points] (1) Load the data into memory and save it to a pandas data frame. Do not normalize or one-hot encode \n",
    "#any of the features until asked to do so later in the rubric. (2) Remove any observations that having missing data. \n",
    "#(3) Encode any string data as integers for now.(Use label encoder) (4) You have the option of keeping the \"county\" variable or removing\n",
    "#it. Be sure to discuss why you decided to keep/remove this variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f2355",
   "metadata": {},
   "source": [
    "We decided to drop the county variable due to the fact that the counties represent political subdivision which are subject to jerrymandering. The tractId is the preferred area identifier employed by the census bureau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87124fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    58174.000000\n",
       "mean         0.211142\n",
       "std          0.185939\n",
       "min          0.000000\n",
       "25%          0.062000\n",
       "50%          0.163000\n",
       "75%          0.316000\n",
       "max          1.000000\n",
       "Name: ChildPoverty, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['ChildPoverty']\n",
    "X = df.drop(['ChildPoverty','County'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y, test_size=0.2)\n",
    "y_train = y_train.div(100)\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b5067a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14655\n",
       "4    14530\n",
       "2    14527\n",
       "3    14462\n",
       "Name: ChildPoverty, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.qcut(y_train,q=4,labels=[1,2,3,4],precision=0)\n",
    "y_train.value_counts()\n",
    "#[.5 points] Balance the dataset so that about the same number of instances are within each class. Choose a method for\n",
    "#balancing the dataset and explain your reasoning for selecting this method. One option is to choose quantization \n",
    "#thresholds for the \"ChildPoverty\" variable that equally divide the data into four classes. Should balancing of the \n",
    "#dataset be done for both the training and testing set? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd894780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3686\n",
       "2    3644\n",
       "4    3640\n",
       "1    2621\n",
       "Name: ChildPoverty, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.cut(y_test, [0, 6.2, 16.3, 31.6, 100],labels=[1,2,3,4],precision=0)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5513849",
   "metadata": {},
   "source": [
    "Here we chose to use the pandas qcut to descretize the feature class into 4 equal-sized based on the sample quantiles which represent the low, medium, high, and extreme child poverty rate classes. The balancing should only be done on the training set because we want the testing set to represent never before seen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train,prefix='ChildPoverty')\n",
    "y_test = pd.get_dummies(y_test,prefix='ChildPoverty')\n",
    "y_train.head()\n",
    "#[.5 points] Assume you are equally interested in the classification performance for each class in the dataset. Split \n",
    "#the dataset into 80% for training and 20% for testing. There is NO NEED to split the data multiple times for this lab.\n",
    "#Note: You will need to one hot encode the target, but do not one hot encode the categorical data until instructed to do so in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08339821",
   "metadata": {},
   "source": [
    "Here, we one-hot encoded the target training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53ed631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import numpy as np \n",
    "\n",
    "y_train = y_train.to_numpy(dtype='int64')\n",
    "X_train = X_train.to_numpy()\n",
    "y_test = y_test.to_numpy(dtype='int64')\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "#You will be using a two layer perceptron from class for the next few parts of the rubric. There are several versions \n",
    "#of the two layer perceptron covered in class, with example code. When selecting an example two layer network from class\n",
    "#be sure that you use: (1) vectorized gradient computation, (2) mini-batching, (3) cross entropy loss, and (4) proper \n",
    "#Glorot initialization, at a minimum. There is no need to use momentum or learning rate reduction (assuming you choose\n",
    "#a sufficiently small learning rate). It is recommended to use sigmoids throughout the network, but not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb778f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58174,)\n",
      "(58174, 35)\n",
      "(14544,)\n",
      "(14544, 35)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339bf134",
   "metadata": {},
   "source": [
    "We have converted all of the training and testing dataframes into numpy arrays. Notice how the number of features for the y_training set is 4 while the y_test set is only 1 feature because it represents an unknown dataset which in reality will be unbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94245f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import sys \n",
    "\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=1,\n",
    "                 C=0.0, epochs=500, eta=0.1, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0,size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1)\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        A1 = A1.T\n",
    "        Z1 = W1 @ A1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        grad2 = V2 @ A2.T\n",
    "        grad1 = V1[1:,:] @ A1.T\n",
    "        \n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc807153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False, XY_test=None):\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        rho_W1_prev = np.zeros(self.W1.shape)\n",
    "        rho_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "            self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            eta = self.eta / (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost)\n",
    "\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                rho_W1, rho_W2 = eta * grad1, eta * grad2\n",
    "                self.W1 -= (rho_W1 + (self.alpha * rho_W1_prev))\n",
    "                self.W2 -= (rho_W2 + (self.alpha * rho_W2_prev))\n",
    "                rho_W1_prev, rho_W2_prev = rho_W1, rho_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83bc74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        V2 = (A3-Y_enc)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        grad2 = V2 @ A2.T\n",
    "        grad1 = V1[1:,:] @ A1.T\n",
    "\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aee0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPBetterInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "        W1[:,:1] = 0\n",
    "        \n",
    "\n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1)) \n",
    "        W2[:,:1] = 0\n",
    "        \n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2076c13a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = { 'n_hidden':1, \n",
    "         'C':0.1, 'epochs':20, 'eta':0.001,'minibatches':50,\n",
    "         'shuffle':True,'random_state':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0694a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "CPU times: total: 15.7 s\n",
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_mini_batch = TLPMiniBatch(**params)\n",
    "\n",
    "nn_mini_batch.fit(X_train, y_train, print_progress=1)\n",
    "yhat = nn_mini_batch.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c88f6a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25343784378437845\n",
      "CPU times: total: 45.8 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_cross_entropy = TLPMiniBatchCrossEntropy(**params)\n",
    "\n",
    "nn_cross_entropy.fit(X_train, y_train, print_progress=1)\n",
    "yhat = nn_cross_entropy.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7189dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25343784378437845\n",
      "CPU times: total: 46.3 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_glorot = TLPBetterInitial(**params)\n",
    "\n",
    "nn_glorot.fit(X_train, y_train, print_progress=1)\n",
    "yhat = nn_glorot.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ad6049c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# take the mean of each minibatch epoch\n",
    "cost_avgs = [np.mean(x) for x in nn_mini_batch.cost_]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91dad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[.5 points] Use the example two-layer perceptron network from the class example and quantify performance using accuracy.\n",
    "#Do not normalize or one-hot encode the data (not yet). Be sure that training converges by graphing the loss function \n",
    "#versus the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[.5 points] Now (1) normalize the continuous numeric feature data. Use the example two-layer perceptron network \n",
    "#from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss \n",
    "#function versus the number of epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[.5 points] Now(1) normalize the continuous numeric feature data AND (2) one hot encode the categorical data. Use the\n",
    "#example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that \n",
    "#training converges by graphing the loss function versus the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1 points] Compare the performance of the three models you just trained. Are there any meaningful differences in \n",
    "#performance? Explain, in your own words, why these models have (or do not have) different performances.  \n",
    "#Use one-hot encoding and normalization on the dataset for the remainder of this lab assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04737a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1 points] Add support for a third layer in the multi-layer perceptron. Add support for saving (and plotting after training \n",
    "#is completed) the average magnitude of the gradient for each layer, for each epoch (like we did in the flipped module\n",
    "#for back propagation). For magnitude calculation, you are free to use either the average absolute values or the L1/L2 norm.\n",
    "#Quantify the performance of the model and graph the magnitudes for each layer versus the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1 points] Repeat the previous step, adding support for a fourth layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1 points] Repeat the previous step, adding support for a fifth layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a65698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[2 points] Implement an adaptive learning technique that was discussed in lecture and use it on the five layer network\n",
    "#(such as AdaGrad, RMSProps, or AdaDelta). Discuss which adaptive method you chose. Compare the performance of your five\n",
    "#layer model with and without the adaptive learning strategy. Do not use AdaM for the adaptive learning technique as it \n",
    "#is part of the exceptional work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceptional Work (1 points total)\n",
    "#One idea (required for 7000 level students):  Implement adaptive momentum (AdaM) in the \n",
    "#five layer neural network and quantify the performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
